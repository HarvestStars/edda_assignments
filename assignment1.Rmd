---
title: "Experimental Design and Data Analysis - Assignment 1"
author: "Group 5 - Ivana Malčić, Xuening Tang, Xiaoxuan Zhang"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
editor_options: 
  markdown: 
    wrap: 72
---

*In order not to be bothered with rounding the numbers, set
`options(digits=3)r options(digits=3)`.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Matrix)
library(dplyr)
library(knitr)
library(kableExtra)
library(moments)
library('MASS')
options(digits = 3)

```

## Exercise 1: Cholesterol

**a)** In this first section, both normality and variable correlation
are explored using relevant plots and metrics. Firstly, the bell-like
shape of the histograms indicates that the data is normally distributed.

```{r, echo=FALSE}
cholesterol_data <- read.delim("cholesterol.txt", sep = " ")
par(mfrow = c(1,2))

#histograms for 'Before' and 'After8weeks'
hist(cholesterol_data$Before, 
     main = "Histogram: Before", 
     xlab = "Cholesterol (Before)", 
     col = "lightblue", 
     border = "black")

hist(cholesterol_data$After8weeks, 
     main = "Histogram: After8weeks", 
     xlab = "Cholesterol (After 8 weeks)", 
     col = "lightcoral", 
     border = "black")
```

The previous finding is further confirmed by the following QQ-plots
where the data points seem relatively close to the reference line, again
signaling normality.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.show="hold"}
par(mfrow = c(1,2))
#QQ-plots for 'Before'
qqnorm(cholesterol_data$Before, main = "QQ Plot: Before")
qqline(cholesterol_data$Before, col = "red")

#QQ-plots for 'After8weeks'
qqnorm(cholesterol_data$After8weeks, main = "QQ Plot: After8weeks")
qqline(cholesterol_data$After8weeks, col = "red")
```

Additional data exploration gives us further insight; the close mean and
median signify symetric distribution, a feature which is also a common
attribute of normality. Moreover, the skewness for both variables tells
us that the left tail is slightly longer (distribution skewed to the
left). Finally, kurtosis of 2.5 and 2.27 indicates a peaked distribution
with less outliers and a more or less uniform distribution.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#calculates descriptive statistics
descriptive_stats <- data.frame(
  Variable = colnames(cholesterol_data),
  Mean = sapply(cholesterol_data, mean, na.rm = TRUE),
  Median = sapply(cholesterol_data, median, na.rm = TRUE),
  Skewness = sapply(cholesterol_data, skewness, na.rm = TRUE),
  Kurtosis = sapply(cholesterol_data, kurtosis, na.rm = TRUE)
)
#removes the row names to avoid duplication
row.names(descriptive_stats) <- NULL

#creates a table using kable
kable(descriptive_stats, caption = "Descriptive Statistics for Cholesterol Levels", align = "c", digits = 2)
```

After normality assesment, we turn to look at whether the two variables
are correlated. For this we first utilize a simple scatterplot shown
below which exhibits strong positive correlation visible by the densly
clustered data points around the rising regression line.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.show="hold"}
par(mfrow = c(1,1))

#simple scatterplot which plots correlation between the two variables
plot(cholesterol_data$Before, cholesterol_data$After8weeks,
     main = "Scatter Plot: Before vs After8weeks",
     xlab = "Cholesterol (Before)",
     ylab = "Cholesterol (After 8 Weeks)",
     pch = 16, col = "blue")
abline(lm(After8weeks ~ Before, data = cholesterol_data), col = "red", lwd = 2)
```

Then, Pearson´s test is employed - the correlation coefficient of 0.991
indicates a strong and positive linear relationship between the two
variables. Furthermore, the small p-value (\<0.001) suggests this
relationship is statistically significant, and therefore we can reject
the null hypothesis of no correlation.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#pearson´s correlation test to quantify level of correlation
correlation_test <- cor.test(cholesterol_data$Before, cholesterol_data$After8weeks, method = "pearson")

correlation_results <- data.frame(
  Statistic = c("Correlation Coefficient", "P-value", "Confidence Interval"),
  Value = c(
    round(correlation_test$estimate, 3),  
    round(correlation_test$p.value, 3),   
    paste(round(correlation_test$conf.int[1], 3), "to", round(correlation_test$conf.int[2], 3))  # Round confidence interval
)

)
#presenting the results in a table
kable(correlation_results, caption = "Pearson Correlation Test Results", align = "l", col.names = c("Statistic", "Value"))
```

**b)** Now, our goal is to establish whether the low-fat margarine diet
had any effect on cholesterol by utilizing 2 relevant test metrics.
Since our data is paired, we first utilize a paired t-test. The large
t-statistic and small p-value (p \< 0.001) provide strong evidence
against the null hypothesis of no difference. Additionally, the
confidence interval suggests that the mean cholesterol level after 8
weekes lies somewhere between 0.54 and 0.718 with 95% confidence.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#perform a paired t-test
t_test_result <- t.test(cholesterol_data$Before, cholesterol_data$After8weeks, paired = TRUE)

#extracting the key results and rounding them to 3 decimal places (the global function did not work here,
#so I manually specified the rounding)
t_test_results <- data.frame(
  Statistic = c("t-statistic", "Degrees of Freedom", "P-value", "Confidence Interval"),
  Value = c(
    round(t_test_result$statistic, 3),  
    round(t_test_result$parameter, 3),  
    round(t_test_result$p.value, 3),    
    paste(round(t_test_result$conf.int[1], 3), "to", round(t_test_result$conf.int[2], 3))  # Round confidence interval
  )
)
#displays the results as a table
kable(t_test_results, caption = "Paired t-Test Results", align = "l", col.names = c("Statistic", "Value"))
```

Since our data are paired and normally distributed, the Mann-Whitney U
test is not applicable in this scenario. However, we can apply the
permutation test which is useful because it works well with small data
volumes. The following permutation table reveals a similar trend as
previously discussed with a statistically significant (p\<0.001) average
decrease in cholesterol levels by 0.629 units after the 8 week
intervention.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Observed mean difference
observed_diff <- mean(cholesterol_data$Before - cholesterol_data$After8weeks)

# Number of permutations
n_permutations <- 10000

# Initialize a vector to store permutation results
permuted_diffs <- numeric(n_permutations)

# Perform permutations
set.seed(123)  # For reproducibility
for (i in 1:n_permutations) {
  # Randomly flip the signs of the differences
  signs <- sample(c(-1, 1), size = nrow(cholesterol_data), replace = TRUE)
  permuted_diff <- mean((cholesterol_data$Before - cholesterol_data$After8weeks) * signs)
  permuted_diffs[i] <- permuted_diff
}

# Calculate the p-value
p_value <- mean(abs(permuted_diffs) >= abs(observed_diff))

# Create a data frame for the results
results_table <- data.frame(
  Statistic = c("Observed Mean Difference", "Permutation Test P-value"),
  Value = c(observed_diff, p_value)
)

# Display the results as a table
kable(results_table, caption = "Permutation Test Results", align = "l", col.names = c("Statistic", "Value"))
```

**c)** Next, we are constructing a 97% CI and 97% bootstrapped CI, as
opposed to our previously used 95% CI. As visible from *Table 5*, we can
be 97% confident our true population parameter is encompased between the
ranges of [5.16, 6.39] for normal CI and [5.23, 6.32] for the
bootstrapped CI.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

x <- cholesterol_data$After8weeks

#calculates the sample mean, standard deviation, and sample size
n <- length(x)
x_bar <- mean(x)
s <- sd(x)


##97% CI.

#finding the critical t-value for a 97% CI
alpha <- 0.03
t_critical <- qt(1 - alpha / 2, df = n - 1)

#calculates the 97% CI based on normality
ci_lower <- x_bar - t_critical * (s / sqrt(n))
ci_upper <- x_bar + t_critical * (s / sqrt(n))


##Bootstrapped 97% CI.

n_bootstrap <- 10000
bootstrap_means <- numeric(n_bootstrap)

set.seed(123)  
for (i in 1:n_bootstrap) {
  bootstrap_sample <- sample(x, size = n, replace = TRUE)
  bootstrap_means[i] <- mean(bootstrap_sample)
}

ci_bootstrap <- quantile(bootstrap_means, probs = c(alpha / 2, 1 - alpha / 2))

#creates a table for the results
result_table <- data.frame(
  Method = c("Normality (t-distribution)", "Bootstrap"),
  Lower_Bound = c(ci_lower, ci_bootstrap[1]),
  Upper_Bound = c(ci_upper, ci_bootstrap[2])
)

kable(result_table, caption = "97% Confidence Intervals for Mean")
```

**d)** Additionally, we use bootstrapping to come up with a 97%
confidence interval for the maximum statistic for various candidate
values of θ, helping us reject or not reject the hypothesis that the
data follow a Uniform[3,θ] distribution. *Table 6* provides us with
plausible candidate values for which we cannot reject the Null
hypothesis. Kolmogorov-Smirnov test can also be applied in this case to
test whether the data follows a uniform distribution.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

x <- cholesterol_data$After8weeks

#test statistic
T_obs <- max(x)

#theta values to test
theta_values <- seq(3, 12, by = 0.1)

rejected <- logical(length(theta_values))

#bootstraped test for each theta
set.seed(123)  
n_bootstrap <- 10000  

for (i in seq_along(theta_values)) {
  theta <- theta_values[i]
  
  #simulates bootstrap samples under H0
  T_bootstrap <- numeric(n_bootstrap)
  for (j in 1:n_bootstrap) {
    bootstrap_sample <- runif(length(x), min = 3, max = theta)
    T_bootstrap[j] <- max(bootstrap_sample)
  }
  
  #checks if T_obs falls within the 97% of the bootstrap distribution
  ci <- quantile(T_bootstrap, probs = c(0.015, 0.985))
  rejected[i] <- T_obs < ci[1] || T_obs > ci[2]
}

#theta values for which H0 is not rejected
theta_not_rejected <- theta_values[!rejected]

results_table <- data.frame(
  Theta = theta_not_rejected,
  Lower_Bound = sapply(theta_not_rejected, function(theta) 
    quantile(replicate(n_bootstrap, max(runif(length(x), 3, theta))), probs = 0.015)),
  Upper_Bound = sapply(theta_not_rejected, function(theta) 
    quantile(replicate(n_bootstrap, max(runif(length(x), 3, theta))), probs = 0.985))
)

knitr::kable(results_table, 
             caption = "Non-Rejected Theta Values",
             align = "c",
             col.names = c("Theta", "Lower Bound", "Upper Bound"))
```

Kolmogorov-Smirnov test can also be applied in this case to test whether
the data follows a uniform distribution.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
p_values <- numeric(length(theta_values))

#performs KS test for each theta
for (i in seq_along(theta_values)) {
  theta <- theta_values[i]
  
  #theoretical uniform distribution
  uniform_cdf <- function(x) {
    ifelse(x < 3, 0, ifelse(x > theta, 1, (x - 3) / (theta - 3)))
  }
  
  #performs the KS test
  ks_test <- ks.test(x, uniform_cdf)
  p_values[i] <- ks_test$p.value
}

#identifies theta values for which H0 is not rejected (p-value > 0.03)
theta_not_rejected_ks <- theta_values[p_values > 0.03]

#performing KS test for each theta
for (i in seq_along(theta_values)) {
  theta <- theta_values[i]
  uniform_cdf <- function(x) {
    ifelse(x < 3, 0, ifelse(x > theta, 1, (x - 3) / (theta - 3)))
  }
  ks_test <- ks.test(x, uniform_cdf)
  p_values[i] <- ks_test$p.value
}

#identifies non-rejected theta values (p-value > 0.03)
theta_not_rejected_ks <- theta_values[p_values > 0.03]

#creates a table
results_ks <- data.frame(
  Theta = theta_not_rejected_ks,
  P_Value = p_values[p_values > 0.03]
)
results_ks$P_Value <- round(results_ks$P_Value, 3)

knitr::kable(results_ks, 
             caption = "Theta Values with Non-Rejected KS Test",
             align = "c",
             col.names = c("Theta", "P-Value"))

```

**e)** Finally, we are testing the following Null hypothesis: *Null
hypothesis (*$H_0$): The median cholesterol level after 8 weeks is 6.
With the results presented below we can conclude there is not enough
statistical evidence to conclude that the median cholesterol level after
8 weeks is less than 6. While 61.1% of the sample is below 6, this
deviation could easily be due to random variation given the sample size
(p\>0.1).

```{r, echo=FALSE, message=FALSE, warning=FALSE}

x <- cholesterol_data$After8weeks
n <- length(x)
n_below6 <- sum(x < 6)

#binomial test: H₀ (telling us the median = 6), P(x < 6) = 0.5
median_test <- binom.test(n_below6, n, p = 0.5, alternative = "greater")

#creates a table summarizing the results 
results_median <- data.frame(
  Statistic = c("Sample Size", "Number < 6", "Observed Proportion", "p-value", "95% CI"),
  Value = c(
    n,
    n_below6,
    round(n_below6 / n, 3),
    round(median_test$p.value, 3),
    paste(round(median_test$conf.int[1], 3), "to", round(median_test$conf.int[2], 3))
  )
)

knitr::kable(results_median, caption = "Median Test Results (H₀: median = 6)")
```

Subsequently, our second Null hypothesis goes as following: *Null
hypothesis (*$H_0$): the fraction of cholesterol levels below 4.5 is at
most 0.25. Similarly, we also cannot reject this hypothesis because of
the very high p-value (p\>0.1) and a wide CI.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

n_below4.5 <- sum(x < 4.5)

#binomial test: H₀ tells us that the fraction below 4.5 = 0.25
fraction_test <- binom.test(n_below4.5, n, p = 0.25, alternative = "greater")

#creates a table
results_fraction <- data.frame(
  Statistic = c("Sample Size", "Number < 4.5", "Observed Proportion", "p-value", "95% CI"),
  Value = c(
    n,
    n_below4.5,
    sprintf('%.3f', n_below4.5 / n),
    sprintf('%.3f', fraction_test$p.value),
    paste0(sprintf('%.3f', fraction_test$conf.int[1]), " to ", sprintf('%.3f', fraction_test$conf.int[2]))
  )
)

knitr::kable(results_fraction, caption = "Fraction Test Results (H₀: fraction below 4.5 is 25%)")
```

## Exercise 2

#### Section a

To study the effect of County and Related on the variable Crops, we
propose the following hypotheses:\
$H_{AB}$ There is no interaction effect of *County and Related*.\
$H_A$ There is no main effect of factor *County*.\
$H_B$ There is no main effect of factor *Related*.

```{r}
library(dplyr)
crop_data <- read.delim("crops.txt", sep = " ") # read the dataset

cropframe = data.frame(
  crops = crop_data$Crops, 
  county = factor(crop_data$County),
  related = factor(crop_data$Related)) # turn variables "county" and "related" into factors; store relevant variables to a new data frame

cropframe <- cropframe %>% mutate(related = recode(related, 'yes' = '1', 'no' = '0')) # recode the "related" variable
```

```{r}
cropframe # display the frame
crops = cropframe$crops
county = cropframe$county
related = cropframe$related
```

Before conducting the ANOVA test, we first plotted two interaction plots
to get a first glimpse of the potential interaction effect. Based on the
two interaction plots, it seems there is little interaction effect, as
the lines are parallel in general. We then conduct a two-way ANOVA to
confirm our observation.

```{r, fig.height=6, fig.width=6}
interaction.plot(related,county,crops) # fix county
interaction.plot(county,related,crops) # fix related
```

```{r}
is.factor(county) # check if county and related are factors
is.factor(related)
```

```{r}
cropanov=lm(crops~county*related); anova(cropanov) # conduct the two-way ANOVA test
summary(cropanov)
```

Result shows that there is no interaction effect between *Related* and
*County* on *Crops*. None of the p values for *County*, *Crops* and
*County:Related* are significant (p = 0.477; p = 0.527; p = 0.879). To
make sure that this result is valid, we plot a Q-Q plot and residual
plot. Based on the two plots, the assumption of normality is met: Q-Q
plot gives a straight line in general, and the residuals display no
pattern.

```{r}
par(mfrow=c(1,2))
qqnorm(residuals(cropanov)); plot(fitted(cropanov),residuals(cropanov))
```

In the next step, we remove the interaction and apply an additive model.
The code and results are shown below:

```{r}
cropanov2=lm(crops~county+related,data=cropframe); anova(cropanov2) # additive model
summary(cropanov2)
```

The result of the additive model shows that neither of the factors has a
significant main effect on Crops. The p-values are 0.4518 and 0.5126 for
*County* and *Related* respectively, and are larger than the 0.05
significance level in both cases. Therefore, we fail to reject none of
our hypotheses. The normality assumption of this ANOVA test is also met
based on the following Q-Q plot and residual plot:

```{r}
qqnorm(residuals(cropanov2)); plot(fitted(cropanov2),residuals(cropanov2))
```

Summary for the decisions to the null hypotheses:

| Hypothesis | Decision   |
|------------|------------|
| $H_{AB}$   | not reject |
| $H_{A}$    | not reject |
| $H_{B}$    | not reject |

The mathematical formula for a two-way ANOVA model is:

$$
Y_{ijk} = \mu_{ij} + e_{ijk}
$$

where

$$
\mu_{ij} = \mu + \alpha_i + \beta_j + \gamma_{ij}
$$

$\mu$ is the overall mean

$\alpha_i$ is the main effect of level i of the factor *County*, i =
1,2,3

$\beta_j$ is the main effect of level j of the factor *Related*, j = 0,1

$\gamma_ij$ is the interaction effect of levels i, j of factor *County*
and *Related*, which is 0 in this case, since there is no significant
interaction effect.

We apply the model **cropanov2** for prediction.Therefore, the crops in
*County 3* for which there is no related is:

$$
Crops = Intercept + County3 + Related0 = 6800.6 + 959.7 + 0 = 7760.3
$$

Therefore, the predicted value of the Crops is 7760.3.

#### Section b

We now add the variable *Size*. Since it is a numerical variable, it
should be treated as an exploratory variable. We want to find out how
*Size* influences the effect of *Related* or *County* on *Crops* in our
model.

(1) ANCOVA test: *Size \* County*

$H_{AB}$ There is no interaction effect between *Size* and *County* on
*Crops*

We first get a glimpse of the distribution of size in different
counties. It seems the distributions are different in different
counties. We need to confirm our observation through a two-way ANCOVA
model.

```{r}
size = crop_data$Size
boxplot(size~county)
```

```{r}
cropanov3=lm(crops~size*county,data=cropframe);anova(cropanov3)
summary(cropanov3)
```

Based on the result, there is a significant interaction effect between
*Size* and *County* on *Crops (p-value = 0.007)*. Summary of the ANOVA
model shows that the effect mainly lies on the combination of
*size:county 2 (p-value = 0.002)*, while size:county 3 is not
significant (p-value = 0.157). Meanwhile, *county 2* also has a
significant main effect under the influence of *Size* (p-value = 0.005).
Q-Q plot and residual plot show that the assumption of normality is met
in this case:

```{r}
qqnorm(residuals(cropanov3)); plot(fitted(cropanov3),residuals(cropanov3))
```

We **reject the null hypothesis** that there is no interaction effect
between *Size* and *County*

2.  ANCOVA test: *Size \* Related*

$H_{AB}$ There is no interaction effect between *Size* and *Related* on
*Crops*

```{r}
boxplot(size~related)
```

```{r}
cropanov4=lm(crops~size*related,data=cropframe);anova(cropanov4)
summary(cropanov4)
```

In the box plot, the distribution of *Size* does not differ much for
different *Related* values. The interaction effect is also not
significant according to the result of the ANCOVA test (p=0.331).
Therefore, we **cannot reject the null hypothesis** in this case. The
assumption of normality is met in general, though one can argue that
there are more residuals on the lower fitted value side.

```{r}
qqnorm(residuals(cropanov4)); plot(fitted(cropanov4),residuals(cropanov4))
```

We then conduct two ANCOVA tests without interaction. We investigate the
main effect of *Related* under the influence of *Size (cropanov5)*, and
the main effect of *Size* under the influence of *Related (cropanov6).*

```{r}
cropanov5=lm(crops~size+related,data=cropframe);anova(cropanov5)# related on the second place
summary(cropanov5)
```

```{r}
cropanov6=lm(crops~related+size,data=cropframe);anova(cropanov6)# size on the second place
summary(cropanov6)
```

Results show that *Related* does not have a significant main effect on
*Crops* under the influence of *Size*, but *Size* has a significant main
effect under the influence of *Related*. The normality assumption of
both of the ANCOVA tests are met in general, although there seems to be
more residuals in the area with a lower fitted score:

```{r}
qqnorm(residuals(cropanov5)); plot(fitted(cropanov5),residuals(cropanov5))
```

```{r}
qqnorm(residuals(cropanov6)); plot(fitted(cropanov4),residuals(cropanov6))
```

Summary of this part:

(1) There is a significant interaction effect between *Size* and
    *County* on *Crops*. The combination *Size:County 2* is making the
    most contribution.

(2) No significant interaction effect is found for *Size \* Related*.

(3) *Related* has no significant main effect on *Crops* under the
    influence of *Size*, while *Size* has a significant main effect on
    *Crops* under the influence of *Related*.

#### Section c

Based on our findings in part (b), we now include all factors (*Related*
and *County*) and the exploratory variable (*Size*) together in the same
model. We conduct a full ANCOVA test.

$$
Crops∼County+Related+Size+(County×Size)+(Related×Size)+(County×Related)
$$

We already know there is no interaction between *Related and Size*, and
*County and Related*, so we drop the last two terms and get:

$$
Crops∼County+Related+Size+(County×Size)
$$

```{r}
cropanov7=lm(crops ~ county+related+size+county*size, data = crop_data);anova(cropanov7)# size on the second place
summary(cropanov7)
```

```{r}
qqnorm(residuals(cropanov7)); plot(fitted(cropanov7),residuals(cropanov7))
```

Result of a full ANCOVA test also confirms what we found in section B in
general. There is a significant main effect of variable *Size (p =
0.000)* and *County 2 (p = 0.008)*. The interaction effect of
*Size:County* is therefore also significant *(p = 0.012)*. Different
from section B, *County* now also has a slightly significant main effect
*(p = 0.016)*, when *County, Related* and *Size* are all included into
the model. The assumption of normality is met according to the Q-Q plot
and residual plot.

Based on the summary, we can derive several conclusions:

-   There is a significant difference between crop values in these three
    counties. County 2 yields significantly fewer crops than County 1
    (Estimate = -4214.050).

-   Size has a significantly positive effect on crops, with a larger
    land results in more crops (Estimate = 22.704).

-   The positive effect of size is more prominent in County 2, as there
    is a significant interaction effect. They yield a higher crops value
    than Size: County1 (Estimate = 26.590).

-   Value of crops does not depend on the relation of landlord and
    tenant in all three counties, ,as the difference between different
    relations is not statistically significant.

The following table summarizes all ANOVA tests we've run in this
exercise: (the ones with bold fonts are used for predictions)

| Name | Test Type | R-model |
|----|----|----|
| cropanov | Two-way ANOVA model | \$ Crops∼(County×Related) \$ |
| **cropanov2** | Additive model | \$ Crops∼(County+Related) \$ |
| cropanov3 | Two-way ANCOVA model | \$ Crops∼(County×Size) \$ |
| cropanov4 | Two-way ANCOVA model | \$ Crops∼(Size×Related) \$ |
| cropanov5 | Additive model | \$ Crops∼(Size+Related) \$ |
| cropanov6 | Additive model | \$ Crops∼(Related+Size) \$ |
| **cropanov7** | Full ANCOVA model | $Crops∼County+Related+Size+(County×Size)$ |

#### Section d

We will apply model **cropanov7** to make the prediction. The
mathematical formula for a full ANCOVA is:

$$ Y_{ijk} = \mu_{ij} + e_{ijk} $$

where

$$
\mu_{ijk} = \mu + \alpha_i + \beta_j + \delta_k + \gamma_{ik}
$$

$\mu$ is the overall mean

$\alpha_i$ is the main effect of level i of the factor *County*, i =
1,2,3

$\beta_j$ is the main effect of level j of the factor *Related*, j = 0,1

$\delta_k$ is the main effect of the exploratory variable Size, k =
1...n

$\gamma_ik$ is the interaction effect of levels i, k of factor *County*
and exploratory variable *Size*.

According to this equation, the crops from County 2 of size 165, and
related landlord and tenant is therefore:

$$
Crops = Intercept + County2 + Related1 + Size 165 + County2*Size165
$$

$$
= 2461.014-4214.050-239.099+22.704*165+26.590*165 = 6141.378
$$

So the final crops value is 6141.378

The error variance is given by:

$$
\hat{\sigma}^2 = \frac{\text{RSS}}{\text{df}}
$$

According to the summary of the **cropanov7,** we then have:$$
\hat{\sigma}^2 = \frac{20277325}{23} = 881623
$$

The error variance is therefore 881623

## Exercise 3: Yield of peas

### Section a

```{r}

library('MASS')

set.seed(123)  # add random seed for reproduce

# initial params
I <- 6  # blocks
J <- 4  # plots per block

# initial data frame
randomized_design <- data.frame(block = rep(1:I, each = J), plot = rep(1:J, times = I))

# for each block b, put (N, P, K) on each 2 plots randomly
for (b in 1:I) {
  plots <- sample(1:J, J, replace = FALSE)  # randomly reorder plots in each block
  
  # put N in the header 2 plots
  randomized_design$N[randomized_design$block == b] <- ifelse(plots %in% plots[1:2], 1, 0)
  
  # randomly put P in 2 plots
  randomized_design$P[randomized_design$block == b] <- ifelse(plots %in% sample(plots, 2), 1, 0)
  
  # randomly put K in 2 plots
  randomized_design$K[randomized_design$block == b] <- ifelse(plots %in% sample(plots, 2), 1, 0)
}

# print the plots
print(randomized_design)


```

### Section b

```{r, fig.height = 6}

# combine those yield in the same block same N, and calc its mean
yield_matrix <- tapply(npk$yield, list(npk$block, npk$N), mean)

# plot bars
barplot(t(yield_matrix), beside = TRUE, col = c("red", "blue"),
        main = "Average Yield per Block for Nitrogen Treatment",
        xlab = "Block", ylab = "Average Yield")
legend("top", legend = c("N=0", "N=1"), fill = c("red", "blue"))


```

This plot illustrates that the average yields for soil treated by N are
higher than for untreated soil. What's more, each block and treatment
tend to have a similar change.

Meanwhile, we here have assigned treatments randomly to each soil within
a block, which reduces the variation and get more precise results.

### Section c

```{r}

data0 = npk
data0$block = as.factor(data0$block)
data0$N = as.factor(data0$N)

```

```{r}

# Two-Way ANOVA
model2way = lm(yield~N*block, data=data0)
anova(model2way)

```

p \> 0.05, which means there is no significant evidence of interaction
effect.

```{r, fig.height = 3.5}
  
interaction.plot(data0$N,data0$block,data0$yield)
interaction.plot(data0$block,data0$N,data0$yield)

```

Interaction plot also display parallel lines, indicating no interaction.

So, we have to try the "additive" model:

```{r}

modeladd <- lm(yield ~ N + block, data = data0)
anova(modeladd)

```

In both cases p \< 0.05, so both factors have a main effect in the
"additive" model.

```{r, fig.height = 3.5}

# Diagnostics:
par(mfrow=c(1,2)) 
qqnorm(residuals(modeladd)); plot(fitted(modeladd),residuals(modeladd))

```

From QQPlot, we can tell that the curve more or less straight, so it is
likely normal. Meanwhile, there is no significant pattern in the fitted
plot, which is good and means the residual is independent and identical.

-   **Was it sensible to include factor block into this model?** From
    the results showed in "additive" model, the p_value of block is
    0.007095 \< 0.05, and the N is the first order in our model, so it
    makes sense to include the block.
-   **Can we also apply the Friedman test for this situation?** No,
    because each block has more than one same value N, meanwhile, the
    treatments are not completely randomized.

### Section d

```{r}

pairwiseP <- lm(yield ~ block*P + N + K, data = data0) 
pairwiseK <- lm(yield ~ block*K + P + N, data = data0) 
pairwiseN <- lm(yield ~ block*N + K + P, data = data0)

```

```{r}

anova(pairwiseP); anova(pairwiseK); anova(pairwiseN)

```

No interaction effect for either of the three, thus we do an additive
model:

```{r}

modeladd2 <- lm(yield ~ block + N + P + K, data = data0); anova(modeladd2)

```

p \< 0.05 for N and K, showing a main effect. p \> 0.05 for P, so we can
conclude that there is no significant effect.

**We conclude that the best model is the additive ANOVA model.**
Additive ANOVA model provides an overall indication of the effects of
each factor N, P, K and block. From the p values we can tell additive
model are better than the pairwise model. Furthermore, the pairwise
models only focus on the interaction between two factors at a time,
lacking the control for others.

### Section e

```{r}
model_d = lm(yield ~ block + N + K + P, data = data0)
summary(model_d)
```

From the summary we can see block 3 is the best in all blocks, and N1 is
better than N0, which means N treated is better, while P and K are
prefered to be untreated. So, the best combination is **(3, 1, 0, 0)**
for (block, N, P, K), leading the largest yield.

### Section f

```{r}

library('MASS')
library('lme4')
data0 = npk

model_mixed <- lmer(yield ~ N+P+K+(1|block),data=data0,REML=FALSE) 
model_fixed <- lm(yield ~  N + P + K + block, data = data0)
anova(model_mixed,model_fixed) 
```

The model comparison results are:

-   AIC: The fixed effects model (AIC = 143.39) is lower than the mixed
    effects model (AIC = 151.03), suggesting better model fit.
-   BIC: The fixed effects model (BIC = 155.17) is also lower,
    reinforcing the AIC results.
-   Log-likelihood: The fixed effects model has a higher log-likelihood
    (-61.695 vs. -69.514), meaning it fits the data better.
-   Chi-square test: χ² = 15.639, p = 0.003544 (significant at p \<
    0.05), indicating that treating block as a fixed effect is more
    appropriate.

The fixed effects model (lm(yield \~ block + N + P + K)) provides a
better fit than the mixed effects model.
